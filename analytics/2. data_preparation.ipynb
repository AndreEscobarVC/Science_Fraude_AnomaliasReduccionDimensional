{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import compress_pickle as cpickle\n",
    "\n",
    "from scripts import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'test'\n",
    "dataset = 'saludmental'\n",
    "\n",
    "basefolder = f'models/{model}/{dataset}/'\n",
    "\n",
    "infolder = basefolder + 'input/data/'\n",
    "configfolder = basefolder + 'config/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGAR DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = utils.GET_LAST_FILE(infolder, 'dataset')\n",
    "dataframe = cpickle.load(filename1)\n",
    "\n",
    "dataframe.columns = dataframe.columns.str.lower()\n",
    "dataframe = utils.ADD_ROWID(dataframe, 'uniqueid')\n",
    "\n",
    "columnas_originales = list(dataframe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINIR TIPO DE DATO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargo un diccionario con los tipos de datos\n",
    "filename2 = utils.GET_LAST_FILE(configfolder + 'sqldtypes_input/', 'table0')\n",
    "config = utils.READ_JSON(filename2)\n",
    "\n",
    "# para cada columna, aplico su tipo de dato\n",
    "for c in list(dataframe.columns):\n",
    "\n",
    "    dt = config[c]['dtype']\n",
    "\n",
    "    if dt == 'str':\n",
    "        dataframe[c] = dataframe[c].astype(str)\n",
    "    elif dt == 'int':\n",
    "        dataframe[c] = dataframe[c].astype(int)\n",
    "    elif dt == 'float':\n",
    "        dataframe[c] = dataframe[c].astype(float)\n",
    "    elif dt == 'datetime':\n",
    "        dataframe[c] = pd.to_datetime(dataframe[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_columns = ['ruttitular', 'rutbeneficiario', 'numerosolicitud', \n",
    "                'idgrupoprestacion','clasificaciongrupo','idsubgrupoprestacion','clasificacionsubgrupo','idaperturaprestacion','clasificacionapertura',\n",
    "                'fechaprestacion', 'fecharecepcionliquidacion', 'prevision', 'rutprestador', 'nombreprestador']\n",
    "\n",
    "infoframe = dataframe.loc[:, info_columns]\n",
    "dataframe = dataframe.drop(info_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codifico columna de prevision\n",
    "dataframe['fonasa'] = np.where(infoframe['prevision'] == 'FONASA', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codifico columna de clasificacion prestacion\n",
    "dataframe = pd.concat([dataframe, pd.get_dummies(infoframe.clasificacionapertura.str.lower(), prefix='clasif', dtype=int)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codifico columna de dias liquidacion\n",
    "# dataframe['slaliquidacion'] = (infoframe.fecharecepcionliquidacion - infoframe.fechaprestacion).dt.days / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_days_dict():\n",
    "\n",
    "    output = {1:31, 2:29, 3:31, 4:30, 5:31, 6:30, 7:31, 8:31, 9:30, 10:31, 11:30, 12:31}\n",
    "    \n",
    "    return output\n",
    "\n",
    "def get_month_sin(x):\n",
    "\n",
    "    month = int(x.split('-')[1])\n",
    "    output = np.sin(((2*np.pi) * (month-1))/11)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def get_month_cos(x):\n",
    "\n",
    "    month = int(x.split('-')[1])\n",
    "    output = np.cos(((2*np.pi) * (month-1))/11)\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_day_sin(x):\n",
    "   \n",
    "    dicto = get_days_dict()\n",
    "\n",
    "    day = int(x.split('-')[2]) \n",
    "    month = int(x.split('-')[1])\n",
    "    output = np.sin(((2*np.pi) * (day-1))/(dicto[month] - 1))\n",
    "    \n",
    "    return output\n",
    "\n",
    "def get_day_cos(x):\n",
    "    \n",
    "    dicto = get_days_dict()\n",
    "\n",
    "    day = int(x.split('-')[2]) \n",
    "    month = int(x.split('-')[1])\n",
    "    output = np.cos(((2*np.pi) * (day-1))/(dicto[month] - 1))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codifico el dia de la fecha\n",
    "dataframe['day_sin'] = infoframe.fechaprestacion.dt.strftime('%Y-%m-%d').apply(lambda x: get_day_sin(x))\n",
    "dataframe['day_cos'] = infoframe.fechaprestacion.dt.strftime('%Y-%m-%d').apply(lambda x: get_day_cos(x))\n",
    "\n",
    "# codifico el mes de la fecha\n",
    "dataframe['month_sin'] = infoframe.fechaprestacion.dt.strftime('%Y-%m-%d').apply(lambda x: get_month_sin(x))\n",
    "dataframe['month_cos'] = infoframe.fechaprestacion.dt.strftime('%Y-%m-%d').apply(lambda x: get_month_cos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codifico los ruts\n",
    "dataframe['titular'] = (infoframe.ruttitular == infoframe.rutbeneficiario).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_extraidas = set(dataframe.columns) - set(columnas_originales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPORTAR DATOS PREPARADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# almaceno el trabajo de variables\n",
    "variables = {}\n",
    "variables['original'] = columnas_originales\n",
    "variables['information'] = list(info_columns)\n",
    "variables['extracted'] = list(columnas_extraidas)\n",
    "variables['selected'] = []\n",
    "\n",
    "# almaceno la informacion a guardar\n",
    "dfs = {'dataset': dataframe, 'information': infoframe, 'variables': variables}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardo el dataset\n",
    "filename3 = infolder + 'prepared' + filename1.split('/')[-1].split('.')[0][-14:] + '.lzma'\n",
    "utils.SAVE_CPICKLE(dfs, filename3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
